---
title: "GPU-Efficient Noise Techniques in Three.js"
date: 2025-04-29
draft: false
description: "Exploring various methods like pre-computed textures, procedural shaders, and vertex noise to optimize real-time noise generation in Three.js for better GPU performance."
tags: ["three.js", "webgl", "gpu", "performance", "optimization", "noise", "shaders", "procedural generation", "texture mapping"]
categories: ["web development", "graphics", "tutorial", "performance"]
custom_html: full-screen
---
<style>
    /* Styles based on .windsurfrules */
  

    .threejs-container { /* Use class selector */
        position: fixed;
        top: 0;
        left: 0;
        width: 100vw; /* Use viewport width */
        height: 100vh; /* Use viewport height */
        z-index: -1;
        /* outline: 1px dashed red; /* Debug outline */
    }

    .threejs-container canvas { /* Style the canvas */
        display: block;
        width: 100%;
        height: 100%;
    }

    .content-container { /* Adjusted styles from rules */
        background: rgba(0, 0, 0, 0.1);
        border-radius: 8px;
        box-shadow: 0 4px 20px rgba(0, 0, 0, 0.5);
        position: relative;
        z-index: 1;
    }
</style>

<!-- Structure based on .windsurfrules -->
<div class="threejs-container"> <!-- Use class -->
  <canvas id="threejs-canvas"></canvas> <!-- Add explicit canvas -->
  <script src="https://cdn.jsdelivr.net/npm/three@0.152.2/build/three.min.js"></script>
  <script> // Move script inside container
    // === Three.js 3D Concentric Maze Background ===
    // Colors
    const BG_COLOR = new THREE.Color(0x0a103d); // darker, less saturated blue
    const MAZE_COLOR = new THREE.Color(0x8B5C2A); // brown

    // Parameters
    const RING_THICKNESS = 0.015; // Tube radius for the tori
    const MAZE_SPACING = 0.12;   // Distance between ring centers
    const NUM_RINGS = 15;        // How many rings to generate
    const CAMERA_DISTANCE_FACTOR = 1.00; // How far out from the last ring the camera starts
    const CAMERA_ANGLE_DEG =30;

    // Mobile detection
    const isMobile = /Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent);

    // Get container and CANVAS
    const container = document.querySelector('.threejs-container'); // Get container by class
    const canvasElement = document.getElementById('threejs-canvas'); // Get canvas by ID

    const renderer = new THREE.WebGLRenderer({ 
        canvas: canvasElement, // Pass canvas element
        antialias: !isMobile,
        alpha: true,
        powerPreference: 'high-performance'
    });
    renderer.setClearColor(BG_COLOR, 1);
    renderer.setPixelRatio(isMobile ? Math.min(window.devicePixelRatio * 0.6, 1.0) : Math.min(window.devicePixelRatio, 2.0));

    // Scene
    const scene = new THREE.Scene();

    // Camera (Perspective)
    const camera = new THREE.PerspectiveCamera(50, window.innerWidth / window.innerHeight, 0.1, 100);
    const outerRadius = (NUM_RINGS - 1) * MAZE_SPACING;
    const cameraDistance = outerRadius * CAMERA_DISTANCE_FACTOR;
    const cameraHeight = cameraDistance * Math.sin(CAMERA_ANGLE_DEG * Math.PI / 180);
    const cameraHorizontalDist = cameraDistance * Math.cos(CAMERA_ANGLE_DEG * Math.PI / 180);

    camera.position.set(-.4, -cameraHorizontalDist, cameraHeight); // Position out along -Y, and up Z (Rotated 90 deg CW)
    camera.lookAt(0, 0, 0); // Look towards the center

    // Lighting
    const ambientLight = new THREE.AmbientLight(0xffffff, 0.5);
    scene.add(ambientLight);
    const directionalLight = new THREE.DirectionalLight(0xffffff, 0.8);
    directionalLight.position.set(5, 10, 7.5);
    scene.add(directionalLight);

    // --- Starfield --- 
    let stars;
    function createStarfield() {
      const starCount = isMobile ? 1000 : 5000; // Reduced particle count for mobile devices
      const starSpread = 50; // How far out the stars spread
      const vertices = [];
      for (let i = 0; i < starCount; i++) {
        // Spherical distribution
        const phi = Math.acos(-1 + (2 * Math.random()));
        const theta = Math.random() * 2 * Math.PI;
        const r = Math.random() * starSpread;

        const x = r * Math.sin(phi) * Math.cos(theta);
        const y = r * Math.sin(phi) * Math.sin(theta);
        const z = r * Math.cos(phi);

        vertices.push(x, y, z);
      }

      const geometry = new THREE.BufferGeometry();
      geometry.setAttribute('position', new THREE.Float32BufferAttribute(vertices, 3));

      const material = new THREE.PointsMaterial({
        color: 0xffffff,
        size: 0.6, // Increased size for brightness
        sizeAttenuation: false, // Stars stay same size regardless of distance
        depthWrite: false // Prevent stars from writing to depth buffer
      });

      stars = new THREE.Points(geometry, material);
      scene.add(stars);
    }
    createStarfield(); // Add stars to the scene

    // --- Maze Geometry and Material ---
    const mazeGroup = new THREE.Group();
    scene.add(mazeGroup);

    const vertexShader = `
      varying vec3 vWorldPosition;
      void main() {
        vec4 worldPosition = modelMatrix * vec4(position, 1.0);
        vWorldPosition = worldPosition.xyz;
        gl_Position = projectionMatrix * viewMatrix * worldPosition;
      }
    `;

    const fragmentShader = `
      precision mediump float;
      uniform vec3 u_mazeColor;
      uniform float u_time;
      uniform float u_mazeSpacing;
      uniform float u_ringBaseRadius;

      varying vec3 vWorldPosition;

      const float PI = 3.14159265359;

      void main() {
        // Solid color without pattern
        vec3 color = u_mazeColor;

        // Maze rotation and gaps
        float spin = mod(u_time * 0.15, 2.0 * PI);
        float theta = atan(vWorldPosition.y, vWorldPosition.x) - spin;
        float mazeSteps = 8.0 + floor(u_ringBaseRadius / u_mazeSpacing) * 2.0;
        float mazeAngle = 2.0 * PI / mazeSteps;
        float sector = mod(theta + PI, mazeAngle);
        float gapAngle = mazeAngle * 0.3;

        if (sector < gapAngle) discard;
        gl_FragColor = vec4(color, 1.0);
      }
    `;

    // Create shared uniforms
    const sharedUniforms = {
      u_time: { value: 0 },
      u_mazeColor: { value: MAZE_COLOR },
      u_mazeSpacing: { value: MAZE_SPACING },
    };

    // Create multiple tori
    const tori = [];
    for (let i = 0; i < NUM_RINGS; i++) {
      const ringRadius = i * MAZE_SPACING;
      // Skip ring 0 (center point)
      if (ringRadius <= 0.0) continue;

      const geometry = new THREE.TorusGeometry(ringRadius, RING_THICKNESS, isMobile ? 8 : 16, isMobile ? 50 : 100); // Adjust segments as needed

      // Create material with shared uniforms and unique ringBaseRadius
      const material = new THREE.ShaderMaterial({
        uniforms: {
          ...sharedUniforms,
          u_ringBaseRadius: { value: ringRadius }, // Pass the base radius
        },
        vertexShader,
        fragmentShader
      });

      const torus = new THREE.Mesh(geometry, material);
      mazeGroup.add(torus);
      tori.push(torus); // Store for cleanup and uniform updates
    }

    // --- Resize Handler ---
    let resizeTimeout;
    function handleResize() {
      if (renderer?.getContext().isContextLost()) {
        cleanupResources();
        init();
      }
      const width = window.innerWidth;
      const height = window.innerHeight * (isMobile ? 1.15 : 1); // Adjust height factor for mobile
      renderer.setSize(width, height);
      camera.aspect = width / height;
      camera.updateProjectionMatrix();
    }

    // Initial setup and event listener
    handleResize(); // Initial size
    window.addEventListener('resize', handleResize);

    // --- Animation Loop ---
    const clock = new THREE.Clock();
    let timeUniform = { value: 0 };

    function animate(time) {
      timeUniform.value = clock.getElapsedTime();

      // Update shared uniforms
      sharedUniforms.u_time.value = timeUniform.value;

      // Optional: Rotate the whole maze group slowly if desired
      mazeGroup.rotation.z = timeUniform.value * 0.05;

      renderer.render(scene, camera);
    }

    renderer.setAnimationLoop(animate);

    // --- Page Visibility API to pause rendering when tab is inactive ---
    document.addEventListener('visibilitychange', () => {
      if (document.visibilityState === 'visible') {
        renderer.setAnimationLoop(animate);
      } else {
        renderer.setAnimationLoop(null);
      }
    });

    // --- Cleanup --- 
    function cleanupResources() {
      if (renderer) renderer.setAnimationLoop(null);
      
      scene.traverse(obj => {
        if (obj.isMesh) {
          if (obj.geometry) obj.geometry.dispose();
          if (obj.material) {
            if (obj.material.map) obj.material.map.dispose();
            if (obj.material.envMap) obj.material.envMap.dispose();
            if (obj.material.uniforms) {
              Object.values(obj.material.uniforms).forEach(uniform => {
                if (uniform.value?.dispose) uniform.value.dispose();
              });
            }
            obj.material.dispose();
          }
        }
      });

      if (renderer) {
        renderer.dispose();
        renderer.forceContextLoss();
      }

      THREE.Cache.clear();
      window.removeEventListener('resize', handleResize);
      window.removeEventListener('beforeunload', cleanupResources);
      window.removeEventListener('pagehide', cleanupResources);
    }

    window.addEventListener('beforeunload', cleanupResources);
    window.addEventListener('pagehide', cleanupResources);
  </script>
</div> <!-- Close threejs-container -->

<!-- Content now follows the container -->
<div class="content-container px-4 py-8 md:px-8 md:py-12 prose prose-invert max-w-3xl mx-auto"> 
<p>Ah, a fellow traveler seeking more efficient paths in the realm of real-time rendering! You're right, calculating complex noise per-pixel every frame can be a real GPU hog. Thankfully, Three.js offers several more GPU-friendly alternatives. Let's explore some of the most common and effective approaches:</p>
<ol>
  <li>
    <p><strong>Pre-computed Noise Textures:</strong></p>
    <ul>
      <li><strong>Concept:</strong> Instead of generating noise on the fly, you calculate the noise texture once (either offline or during the scene loading) and then sample from this texture in your shaders.</li>
      <li><strong>How it works:</strong> You can use various tools or libraries (like `simplex-noise` in JavaScript) to generate a 2D or 3D noise texture. This texture is then loaded into Three.js as a `Texture` and passed as a uniform to your materials. In your shader, you use the UV coordinates (for 2D) or world position (for 3D) to sample the pre-computed noise value.</li>
      <li><strong>GPU Efficiency:</strong> This is significantly more efficient because the complex noise calculation happens only once, not per-pixel per frame. The GPU only performs a texture lookup, which is a highly optimized operation.</li>
      <li><strong>Considerations:</strong>
        <ul>
          <li><strong>Memory Usage:</strong> Larger or higher-resolution noise textures will consume more GPU memory.</li>
          <li><strong>Static Nature:</strong> The noise pattern is static unless you explicitly update the texture (which can still be less expensive than per-pixel calculation).</li>
          <li><strong>Tiling:</strong> You might need to handle tiling artifacts if your UVs or positions go beyond the texture boundaries.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p><strong>Procedural Noise with Simplified Shader Functions:</strong></p>
    <ul>
      <li><strong>Concept:</strong> Implement a simpler noise algorithm directly within your shader. While still procedural, these algorithms are designed to be less computationally intensive than complex noise functions.</li>
      <li><strong>How it works:</strong> You write GLSL code in your vertex or fragment shader that generates a noise-like pattern based on input parameters like UV coordinates, world position, or time. Simpler algorithms like value noise with fewer octaves or basic gradient noise implementations can be used.</li>
      <li><strong>GPU Efficiency:</strong> More efficient than complex per-pixel noise because the calculations within the shader are streamlined.</li>
      <li><strong>Considerations:</strong>
        <ul>
          <li><strong>Quality:</strong> Simplified noise algorithms might not produce the same level of detail or visual complexity as more advanced methods.</li>
          <li><strong>Shader Complexity:</strong> While simpler, the shader will still perform calculations per-pixel. Careful optimization of the noise function is crucial.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p><strong>Noise Libraries Optimized for Shaders:</strong></p>
    <ul>
      <li><strong>Concept:</strong> Utilize GLSL noise libraries that are specifically designed for GPU performance. These libraries often contain optimized implementations of various noise algorithms.</li>
      <li><strong>How it works:</strong> You include the GLSL code from these libraries directly into your shader. They provide functions you can call to generate noise based on your inputs.</li>
      <li><strong>GPU Efficiency:</strong> These libraries are often written with performance in mind, leveraging GPU-friendly operations and minimizing complex branching or calculations.</li>
      <li><strong>Considerations:</strong>
        <ul>
          <li><strong>Integration:</strong> You need to manage and include the GLSL code within your Three.js shader material.</li>
          <li><strong>Learning Curve:</strong> Understanding how to use the specific functions provided by the library might require some learning.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p><strong>Using Built-in Textures and Transformations:</strong></p>
    <ul>
      <li><strong>Concept:</strong> Leverage existing texture patterns (like gradients, patterns, or even simpler noise textures) and animate or transform their UV coordinates or the object's geometry to create the illusion of dynamic noise.</li>
      <li><strong>How it works:</strong> You can use `TextureLoader` to load simple grayscale textures. In your shader, you can then manipulate the UV coordinates based on time or other parameters to make the texture appear to move, scale, or rotate, creating a dynamic effect. Alternatively, you can animate the object's vertices in the vertex shader based on time or other inputs to create wave-like or turbulent motions.</li>
      <li><strong>GPU Efficiency:</strong> This is generally very efficient as it relies on optimized texture sampling and relatively simple transformations.</li>
      <li><strong>Considerations:</strong>
        <ul>
          <li><strong>Visual Complexity:</strong> The resulting effects might be less intricate than true procedural noise.</li>
          <li><strong>Creativity:</strong> Requires clever manipulation of textures and transformations to achieve desired results.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p><strong>Vertex-Based Noise and Interpolation:</strong></p>
    <ul>
      <li><strong>Concept:</strong> Calculate noise or displacement at the vertices of your geometry in the vertex shader and then let the GPU's rasterizer interpolate these values across the faces.</li>
      <li><strong>How it works:</strong> In your vertex shader, you calculate a noise value (using a pre-computed texture or a simple procedural function) based on the vertex position. You can then use this noise value to displace the vertex along its normal or in other directions. The fragment shader then interpolates these displaced positions and potentially other vertex attributes (like noise values) across the surface.</li>
      <li><strong>GPU Efficiency:</strong> Significantly reduces per-pixel calculations as the noise is only evaluated per vertex. The interpolation is handled efficiently by the GPU.</li>
      <li><strong>Considerations:</strong>
        <ul>
          <li><strong>Detail:</strong> The level of detail in the noise effect is limited by the vertex density of your geometry. Lower poly counts will result in smoother, less detailed noise.</li>
          <li><strong>Silhouette:</strong> The displacement affects the object's silhouette.</li>
        </ul>
      </li>
    </ul>
  </li>
</ol>

<p><strong>Which approach is best?</strong> It often depends on the specific requirements of your scene:</p>
<ul>
  <li>For highly detailed but mostly static noise, <strong>pre-computed textures</strong> are excellent.</li>
  <li>For simpler, dynamic patterns, <strong>simplified shader functions</strong> or <strong>texture transformations</strong> can be very effective.</li>
  <li>When visual quality and complexity are paramount but you still need better performance than raw per-pixel noise, <strong>optimized GLSL libraries</strong> or <strong>vertex-based noise</strong> are good choices.</li>
</ul>

<p>Often, a combination of techniques yields the best balance between visual fidelity and performance. Experiment and profile to see what works best for your particular use case!</p>

</div>

<script src="/js/custom.js"></script>
